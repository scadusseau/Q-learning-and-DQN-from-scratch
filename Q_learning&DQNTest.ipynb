{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q-learning&DQNTest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scadusseau/Q-learning-and-DQN-from-scratch/blob/master/Q_learning%26DQNTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwDNeLRF6s5U",
        "colab_type": "text"
      },
      "source": [
        "# Testing our Q-Learning algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3uSOrt86xd8",
        "colab_type": "text"
      },
      "source": [
        "# Importing the main libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yScroaaL55Ni",
        "colab_type": "code",
        "outputId": "3618a6f2-738f-4cf8-aedb-42da4292069a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31mqWnDR7iXK",
        "colab_type": "text"
      },
      "source": [
        "# Setting the environnement\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFmOEedu7l8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make('FrozenLake-v0')\n",
        "  \n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW-puc97Ufaz",
        "colab_type": "text"
      },
      "source": [
        "# Algorithm Without using a neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81f3czvBUjqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#definition de la fonction:\n",
        "\n",
        "def Qlearning(alpha,gamma,env):\n",
        "\n",
        "#Initialisation de la table\n",
        "  sTaille = env.observation_space.n\n",
        "  aTaille = env.action_space.n\n",
        "  Q = np.zeros([sTaille,aTaille])\n",
        "\n",
        "#Paramètres d'apprentissages\n",
        "  #alpha = 0.8\n",
        "  #gamma = 0.95\n",
        "  nEpisode = 5000\n",
        "\n",
        "#La liste des recompenses totales par episode\n",
        "  ListeR = []\n",
        "\n",
        "  for i in range(nEpisode):  \n",
        "    #Définir l'environnement de départ\n",
        "    s = env.reset()#Renvoie l'état et le met à 0\n",
        "    resTot = 0\n",
        "    Fin = False\n",
        "    nbActions = 0\n",
        "    while nbActions < 99:\n",
        "      nbActions+=1\n",
        "      #if (i<nEpisode-100):\n",
        "      epsilonG = 1/(i+1)\n",
        "      #else:\n",
        "      #epsilon = 0\n",
        "    \n",
        "      a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*epsilonG) \n",
        "    \n",
        "      s_suiv,recompense,Fin,info = env.step(a)\n",
        "      resTot += recompense\n",
        "    \n",
        "      Q[s,a] += alpha*(recompense + gamma * np.max(Q[s_suiv, :]) - Q[s,a])\n",
        "    \n",
        "      s=s_suiv\n",
        "    \n",
        "      if Fin == True:\n",
        "        break\n",
        "    ListeR.append(resTot)\n",
        "   \n",
        "  score = sum(ListeR[4900:])/100\n",
        "  return score\n",
        "    \n",
        "   \n",
        "\n",
        "\n",
        "#print(\"Score over time: \" +  str(sum(ListeR[4900:])/100)) \n",
        "#print(ListeR)\n",
        "#print(Q)\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AesP3KXFhLiX",
        "colab_type": "text"
      },
      "source": [
        "# alpha and gamma optimization with a gradient descent\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa17KZX7hla_",
        "colab_type": "code",
        "outputId": "70d79fe6-1c7b-4cf1-b008-ef88843bc382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# definition du gradient d'une fonction (nabla pour les intimes)\n",
        "\n",
        "def gradient(f,f1_suiv,f2_suiv,x1,x2,x1_suiv,x2_suiv):\n",
        "  grad1 = (f1_suiv - f)/(x1_suiv - x1)\n",
        "  grad2 = (f2_suiv - f)/(x2_suiv - x2)\n",
        "  res = [grad1,grad2]\n",
        "  return res\n",
        "\n",
        "def fonction(alpha,gamma,env):\n",
        "  L = []\n",
        "  \n",
        "  for i in range(0,3):\n",
        "    L.append(Qlearning(alpha,gamma,env))\n",
        "  \n",
        "  res = (1 - sum(L)/3)**2  #on calcule le score moyen defini plus haut de l'algorithme Qlearning  \n",
        "  \n",
        "  return res\n",
        "\n",
        "def Qmoy(alpha,gamma,env):\n",
        "  L = []\n",
        "  \n",
        "  for i in range(0,10):\n",
        "    L.append(Qlearning(alpha,gamma,env))\n",
        "  \n",
        "  res = (sum(L)/10)  \n",
        "  \n",
        "  return res\n",
        "\n",
        "\n",
        "# initialisation des parametres:\n",
        "alpha = 0.8 #variable 1\n",
        "gamma = 0.95 #variable 2\n",
        "max_iters = 100\n",
        "pas = 0.001\n",
        "eps = 0.0001\n",
        "\n",
        "x1 = alpha \n",
        "x2 = gamma\n",
        "\n",
        "for i in range(max_iters):\n",
        "  print(i)\n",
        "  \n",
        "  x1_suiv = x1 + pas\n",
        "  x2_suiv = x2 + pas \n",
        "  \n",
        "  f = fonction(x1,x2,env)\n",
        "  \n",
        "  f1_suiv = fonction(x1_suiv,x2,env)\n",
        "  f2_suiv = fonction(x1,x2_suiv,env)\n",
        "  \n",
        "  #Calcul du gradient\n",
        "  \n",
        "  gradf = gradient(f,f1_suiv,f2_suiv,x1,x2,x1_suiv,x2_suiv)\n",
        "  \n",
        "  #Test d'arret\n",
        "  if gradf[0] <= eps and gradf[1] <= eps:\n",
        "    break\n",
        "   \n",
        "  else:\n",
        "    #incrementation des parametres\n",
        "    x1 = x1 - pas * gradf[0]\n",
        "    x2 = x2 - pas * gradf[1]\n",
        "    \n",
        "\n",
        "alpha,gamma = x1,x2\n",
        "print(\"Fin\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "Fin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Oi8nrPwcL8",
        "colab_type": "code",
        "outputId": "da3b7aee-61dd-410e-9276-070c3b65a2a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "print(\"alpha opt = \" + str(x1) + \"\\ngamma opt = \" + str(x2))\n",
        "print(\"score pour ces valeurs : \" + str(Qmoy(alpha,gamma,env)))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alpha opt = 0.6914555555555556\n",
            "gamma opt = 0.7789666666666667\n",
            "score pour ces valeurs : 0.348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lDPupk309DB",
        "colab_type": "text"
      },
      "source": [
        "# DQN Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeK14BaJsc0V",
        "colab_type": "code",
        "outputId": "bb900e08-80ad-429d-9f0b-f079b8d93e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!pip install keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI2BfMuV1hLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Activation, Flatten\n",
        "from keras.callbacks import TensorBoard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrdu59Vj1kRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQNAgent:\n",
        "  #Ici on s'occupe de mettre en place le réseaux de neurones, on crée les layers dans le model\n",
        "  def create_model(self):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(256, (3,3), input_shape=env.OBSERVATION_SPACE_VALUES))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(2, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beEym5pY1xNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Sbus60ZsW1r",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}